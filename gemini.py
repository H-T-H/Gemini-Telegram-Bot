import io
import time
import traceback
import sys
import os # Added for os.remove
from PIL import Image
from telebot.types import Message
from md2tgmd import escape
from telebot import TeleBot
from config import conf, generation_config, messages, safety_settings # Ensure safety_settings is imported
import google.generativeai as genai # Use alias for consistency
from typing import Optional

# --- System Prompt Management ---
SYSTEM_PROMPT_FILE = "system_prompt.txt"
current_system_prompt = None

def load_system_prompt():
    """Loads the system prompt from SYSTEM_PROMPT_FILE into current_system_prompt."""
    global current_system_prompt
    try:
        with open(SYSTEM_PROMPT_FILE, "r", encoding="utf-8") as f:
            prompt_content = f.read().strip()
            if prompt_content:
                current_system_prompt = prompt_content
            else:
                current_system_prompt = None # Handle empty file as no prompt
    except FileNotFoundError:
        current_system_prompt = None
    print(f"System prompt loaded: {current_system_prompt}")

def save_system_prompt(text: Optional[str]):
    """Saves the system prompt to file, updates current_system_prompt, and clears chat dicts."""
    global current_system_prompt
    
    # Clear all chat histories because system prompt change invalidates them
    gemini_chat_dict.clear()
    gemini_pro_chat_dict.clear()
    # ç§»é™¤ä¸å†ä½¿ç”¨çš„å­—å…¸å¼•ç”¨
    # gemini_draw_dict.clear() 

    if text and text.strip():
        with open(SYSTEM_PROMPT_FILE, "w", encoding="utf-8") as f:
            f.write(text.strip())
        current_system_prompt = text.strip()
    else: # Delete prompt if text is None or empty
        try:
            os.remove(SYSTEM_PROMPT_FILE)
        except FileNotFoundError:
            pass # Already removed or never existed
        current_system_prompt = None
    print(f"System prompt saved: {current_system_prompt}")

# Load system prompt when module is imported
load_system_prompt()
# --- End System Prompt Management ---

# ç§»é™¤ä¸å†ä½¿ç”¨çš„å­—å…¸
# gemini_draw_dict = {}
gemini_chat_dict = {}
gemini_pro_chat_dict = {}
default_model_dict = {}
language_dict = {}  # ç”¨æˆ·è¯­è¨€åå¥½å­—å…¸

model_1 = conf["model_1"]
model_2 = conf["model_2"]
default_language = conf["default_language"]

search_tool = {'google_search': {}} # Assuming this is correctly defined or None if not used

# IMPORTANT: genai.configure(api_key=YOUR_API_KEY) must be called in your main entry point (e.g., main.py)
# Remove old client: client = genai.Client(api_key=sys.argv[2])

# èŽ·å–ç”¨æˆ·è¯­è¨€
def get_user_language(user_id):
    user_id_str = str(user_id)
    if user_id_str not in language_dict:
        language_dict[user_id_str] = default_language
    return language_dict[user_id_str]

# èŽ·å–ç”¨æˆ·æ¶ˆæ¯
def get_message(message_key, user_id):
    lang = get_user_language(user_id)
    return messages[lang][message_key]

async def gemini_stream(bot:TeleBot, message:Message, m:str, model_type:str):
    user_id = message.from_user.id
    sent_message = None
    try:
        sent_message = await bot.reply_to(message, get_message("generating_answers", user_id))

        chat_session_dict = gemini_chat_dict if model_type == model_1 else gemini_pro_chat_dict
        
        if str(user_id) not in chat_session_dict:
            print(f"Creating new chat for {user_id} with system prompt: {current_system_prompt}")
            
            # å°è¯•åˆ›å»ºæ¨¡åž‹å®žä¾‹ï¼Œå¹¶å¤„ç†å„ç§åº“ç‰ˆæœ¬å·®å¼‚
            try:
                # æž„å»ºä¸€ä¸ªå¸¦æœ‰ç³»ç»Ÿæç¤ºçš„æ¨¡åž‹é…ç½®
                model_config = {
                    "model_name": model_type,
                    "generation_config": generation_config
                }
                
                # å¦‚æžœæœ‰ç³»ç»Ÿæç¤ºï¼Œæ·»åŠ å®ƒ
                if current_system_prompt:
                    model_config["system_instruction"] = current_system_prompt
                
                # å¦‚æžœæœ‰å®‰å…¨è®¾ç½®ï¼Œæ·»åŠ å®ƒ
                if safety_settings:
                    model_config["safety_settings"] = safety_settings
                
                # å°è¯•åˆ›å»ºæ¨¡åž‹
                model = genai.GenerativeModel(**model_config)
                
                # å°è¯•å¯åŠ¨èŠå¤©ä¼šè¯
                try:
                    # å¦‚æžœæ”¯æŒå¼‚æ­¥APIï¼Œä½¿ç”¨å®ƒ
                    if hasattr(model, "start_chat"):
                        chat = model.start_chat(history=[])
                    else:
                        # å¦‚æžœä¸æ”¯æŒèŠå¤©ä¼šè¯ï¼Œä½¿ç”¨ç”Ÿæˆå†…å®¹API
                        # è¿™æ˜¯ä¸€ä¸ªé™çº§æ–¹æ¡ˆï¼Œå¯èƒ½æ— æ³•ä¿æŒä¸Šä¸‹æ–‡
                        chat = model
                    
                    chat_session_dict[str(user_id)] = chat
                except Exception as chat_err:
                    print(f"Error starting chat: {chat_err}")
                    # é™çº§ä¸ºç®€å•æ¨¡åž‹
                    chat = model
                    chat_session_dict[str(user_id)] = chat
            except Exception as model_err:
                print(f"Error creating model: {model_err}")
                await bot.edit_message_text(
                    f"Error creating model: {str(model_err)}",
                    chat_id=sent_message.chat.id,
                    message_id=sent_message.message_id
                )
                return
        else:
            chat = chat_session_dict[str(user_id)]

        # å°è¯•å‘é€æ¶ˆæ¯å¹¶å¤„ç†å“åº”
        try:
            # å°è¯•ä½¿ç”¨æµå¼APIï¼Œå¦‚æžœå¯ç”¨
            if hasattr(chat, "send_message_async"):
                response_stream = await chat.send_message_async(m, stream=True)
                
                full_response = ""
                last_update = time.time()
                update_interval = conf["streaming_update_interval"]

                async for chunk in response_stream:
                    if hasattr(chunk, 'text') and chunk.text:
                        full_response += chunk.text
                        current_time = time.time()

                        if current_time - last_update >= update_interval:
                            try:
                                await bot.edit_message_text(
                                    escape(full_response),
                                    chat_id=sent_message.chat.id,
                                    message_id=sent_message.message_id,
                                    parse_mode="MarkdownV2"
                                )
                            except Exception as e:
                                if "parse markdown" in str(e).lower():
                                    await bot.edit_message_text(
                                        full_response,
                                        chat_id=sent_message.chat.id,
                                        message_id=sent_message.message_id
                                    )
                                elif "message is not modified" not in str(e).lower():
                                    print(f"Error updating message: {e}")
                            last_update = current_time
            else:
                # å¦‚æžœä¸æ”¯æŒæµå¼APIï¼Œä½¿ç”¨æ™®é€šAPI
                print("Streaming not available, using standard API")
                if hasattr(chat, "send_message"):
                    response = chat.send_message(m)
                elif hasattr(chat, "generate_content"):
                    response = chat.generate_content(m)
                else:
                    raise Exception("Neither send_message nor generate_content methods available")
                
                # å¤„ç†å“åº”
                full_response = ""
                if hasattr(response, "text"):
                    full_response = response.text
                elif hasattr(response, "parts") and len(response.parts) > 0:
                    for part in response.parts:
                        if hasattr(part, "text"):
                            full_response += part.text
            
            # æœ€ç»ˆæ›´æ–°æ¶ˆæ¯
            try:
                await bot.edit_message_text(
                    escape(full_response) if full_response else "No content generated.",
                    chat_id=sent_message.chat.id,
                    message_id=sent_message.message_id,
                    parse_mode="MarkdownV2"
                )
            except Exception as e:
                if "parse markdown" in str(e).lower():
                    await bot.edit_message_text(
                        full_response if full_response else "No content generated.",
                        chat_id=sent_message.chat.id,
                        message_id=sent_message.message_id
                    )
                elif "message is not modified" not in str(e).lower():
                    traceback.print_exc()
        except Exception as stream_err:
            print(f"Error in streaming: {stream_err}")
            await bot.edit_message_text(
                f"Error processing response: {str(stream_err)}",
                chat_id=sent_message.chat.id,
                message_id=sent_message.message_id
            )

    except Exception as e:
        traceback.print_exc()
        error_msg_key = 'error_info'
        error_details_key = 'error_details'
        # Attempt to get localized error messages
        try:
            error_message_text = f"{get_message(error_msg_key, user_id)}\n{get_message(error_details_key, user_id)}{str(e)}"
        except Exception: # Fallback if get_message fails (e.g., during init)
             error_message_text = f"An error occurred: {str(e)}"

        if sent_message:
            await bot.edit_message_text(
                error_message_text,
                chat_id=sent_message.chat.id,
                message_id=sent_message.message_id
            )
        else:
            await bot.reply_to(message, error_message_text)

async def gemini_edit(bot: TeleBot, message: Message, m: str, photo_file: bytes):
    user_id = message.from_user.id
    pil_image = Image.open(io.BytesIO(photo_file))
    sent_message = None
    
    try:
        sent_message = await bot.reply_to(message, get_message("generating_answers", user_id))
        print(f"Using system prompt for edit: {current_system_prompt}")
        
        # å°è¯•åˆ›å»ºæ¨¡åž‹å®žä¾‹ï¼Œå¹¶å¤„ç†å„ç§åº“ç‰ˆæœ¬å·®å¼‚
        try:
            # æž„å»ºä¸€ä¸ªå¸¦æœ‰ç³»ç»Ÿæç¤ºçš„æ¨¡åž‹é…ç½®
            model_config = {
                "model_name": model_2,
                "generation_config": generation_config
            }
            
            # å¦‚æžœæœ‰ç³»ç»Ÿæç¤ºï¼Œæ·»åŠ å®ƒ
            if current_system_prompt:
                model_config["system_instruction"] = current_system_prompt
            
            # å¦‚æžœæœ‰å®‰å…¨è®¾ç½®ï¼Œæ·»åŠ å®ƒ
            if safety_settings:
                model_config["safety_settings"] = safety_settings
            
            # å°è¯•åˆ›å»ºæ¨¡åž‹
            model = genai.GenerativeModel(**model_config)
            
            # å‡†å¤‡å†…å®¹
            contents = []
            if m and m.strip():
                contents.append(m)
            contents.append(pil_image)
            
            # å°è¯•ç”Ÿæˆå†…å®¹
            try:
                if hasattr(model, "generate_content_async"):
                    response = await model.generate_content_async(contents=contents)
                else:
                    # å¦‚æžœä¸æ”¯æŒå¼‚æ­¥APIï¼Œä½¿ç”¨åŒæ­¥API
                    response = model.generate_content(contents=contents)
                
                # æå–æ–‡æœ¬
                text_response = ""
                if hasattr(response, "text"):
                    text_response = response.text
                elif hasattr(response, "parts") and len(response.parts) > 0:
                    for part in response.parts:
                        if hasattr(part, "text") and part.text:
                            text_response += part.text
                
                # å›žå¤
                if text_response:
                    try:
                        await bot.edit_message_text(
                            escape(text_response),
                            chat_id=sent_message.chat.id,
                            message_id=sent_message.message_id,
                            parse_mode="MarkdownV2"
                        )
                    except Exception as md_err:
                        if "parse markdown" in str(md_err).lower():
                            await bot.edit_message_text(
                                text_response,
                                chat_id=sent_message.chat.id,
                                message_id=sent_message.message_id
                            )
                        else:
                            raise md_err
                else:
                    await bot.edit_message_text(
                        "No text response generated.",
                        chat_id=sent_message.chat.id,
                        message_id=sent_message.message_id
                    )
            except Exception as gen_err:
                print(f"Error generating content: {gen_err}")
                await bot.edit_message_text(
                    f"Error generating content: {str(gen_err)}",
                    chat_id=sent_message.chat.id,
                    message_id=sent_message.message_id
                )
        except Exception as model_err:
            print(f"Error creating model: {model_err}")
            await bot.edit_message_text(
                f"Error creating model: {str(model_err)}",
                chat_id=sent_message.chat.id,
                message_id=sent_message.message_id
            )
    except Exception as e:
        traceback.print_exc()
        error_msg_key = 'error_info'
        # Attempt to get localized error messages
        try:
            error_message_text = f"{get_message(error_msg_key, user_id)}: {str(e)}"
        except Exception: # Fallback if get_message fails
             error_message_text = f"Error in gemini_edit: {str(e)}"
        
        if sent_message:
            await bot.edit_message_text(
                error_message_text,
                chat_id=sent_message.chat.id,
                message_id=sent_message.message_id
            )
        else:
            await bot.send_message(message.chat.id, error_message_text)

async def gemini_draw(bot:TeleBot, message:Message, m:str):
    user_id = message.from_user.id
    sent_message = None # To hold the "Drawing..." message
    try:
        sent_message = await bot.reply_to(message, get_message("drawing", user_id))
        
        # èŽ·å–é…ç½®çš„æ¨¡åž‹åç§°ï¼Œå¦‚æžœæœªé…ç½® model_3ï¼Œåˆ™æä¾›ä¸€ä¸ªå¤‡ç”¨å€¼æˆ–æŠ›å‡ºé”™è¯¯
        # è¿™é‡Œæˆ‘ä»¬å‡è®¾ model_3 æ€»æ˜¯é…ç½®å¥½çš„ï¼Œå› ä¸ºç”¨æˆ·åˆšåˆšæ·»åŠ äº†å®ƒ
        draw_model_name = conf.get("model_3", "gemini-2.0-flash-exp") # ä½¿ç”¨ model_3

        # å°è¯•åˆ›å»ºæ¨¡åž‹å®žä¾‹
        try:
            model_config_params = {
                "model_name": draw_model_name,
                # generation_config å…¨å±€çš„å¯èƒ½ä¸ºç©ºï¼Œæˆ–è€…ä¸åŒ…å« mime_type
            }
            
            # å¦‚æžœæœ‰å…¨å±€ safety_settingsï¼Œæ·»åŠ å®ƒ
            if safety_settings:
                model_config_params["safety_settings"] = safety_settings
            
            # å¦‚æžœæœ‰ç³»ç»Ÿæç¤ºï¼Œæ·»åŠ å®ƒ (è™½ç„¶å¯¹äºŽç»˜å›¾å¯èƒ½ä¸å¸¸ç”¨)
            if current_system_prompt:
                model_config_params["system_instruction"] = current_system_prompt
            
            model = genai.GenerativeModel(**model_config_params)
            
            # å‡†å¤‡ç”Ÿæˆå›¾åƒçš„ç‰¹å®šé…ç½®
            image_generation_config = genai.types.GenerationConfig(
                response_mime_type="image/png"
            )

            # å°è¯•ç”Ÿæˆå†…å®¹
            try:
                # ç¡®ä¿å†…å®¹æ˜¯åˆ—è¡¨å½¢å¼ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªæ–‡æœ¬æç¤º
                contents_for_draw = [m]

                if hasattr(model, "generate_content_async"):
                    response = await model.generate_content_async(
                        contents=contents_for_draw,
                        generation_config=image_generation_config # æŒ‡å®šè¾“å‡ºä¸ºå›¾åƒ
                    )
                else:
                    # åŒæ­¥å›žé€€ (è™½ç„¶å¯¹äºŽboté€šå¸¸å¸Œæœ›å¼‚æ­¥)
                    response = model.generate_content(
                        contents=contents_for_draw,
                        generation_config=image_generation_config # æŒ‡å®šè¾“å‡ºä¸ºå›¾åƒ
                    )
                
                # å¤„ç†å›¾åƒå“åº”
                if response.parts and response.parts[0].inline_data and response.parts[0].inline_data.mime_type == "image/png":
                    image_data = response.parts[0].inline_data.data
                    if sent_message: # åˆ é™¤ "Drawing..." æ¶ˆæ¯
                        await bot.delete_message(chat_id=sent_message.chat.id, message_id=sent_message.message_id)
                        sent_message = None
                    await bot.send_photo(message.chat.id, photo=image_data, caption=f"ðŸ–¼ï¸: {m}")
                else:
                    # å¦‚æžœæ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒéƒ¨åˆ†ï¼Œåˆ™æŠ¥å‘Šé”™è¯¯æˆ–æ„å¤–çš„å“åº”
                    no_image_message = "Failed to generate image or unexpected response format."
                    if hasattr(response, 'prompt_feedback') and response.prompt_feedback.block_reason:
                        no_image_message += f" Reason: {response.prompt_feedback.block_reason_message or response.prompt_feedback.block_reason}"
                    elif response.parts and response.parts[0].text: # å¯èƒ½æ˜¯æ¨¡åž‹è¿”å›žäº†æ–‡æœ¬é”™è¯¯
                         no_image_message += f" Model said: {response.parts[0].text}"
                    
                    if sent_message:
                        await bot.edit_message_text(
                            no_image_message,
                            chat_id=sent_message.chat.id,
                            message_id=sent_message.message_id
                        )
                    else:
                        await bot.reply_to(message, no_image_message)

            except Exception as gen_err:
                print(f"Error generating image content: {gen_err}")
                error_text = f"Error generating image: {str(gen_err)}"
                if hasattr(gen_err, 'args') and len(gen_err.args) > 0 and isinstance(gen_err.args[0], str) and "Deadline Exceeded" in gen_err.args[0]:
                    error_text = "Image generation timed out. Please try a simpler prompt or try again later."

                if sent_message:
                    await bot.edit_message_text(
                        error_text,
                        chat_id=sent_message.chat.id,
                        message_id=sent_message.message_id
                    )
                else:
                    await bot.reply_to(message, error_text)
        
        except Exception as model_err:
            print(f"Error creating draw model: {model_err}")
            if sent_message:
                await bot.edit_message_text(
                    f"Error creating draw model: {str(model_err)}",
                    chat_id=sent_message.chat.id,
                    message_id=sent_message.message_id
                )
            else:
                await bot.reply_to(message, f"Error creating draw model: {str(model_err)}")

    except Exception as e:
        traceback.print_exc()
        error_msg_key = 'error_info'
        error_details_key = 'error_details'
        try:
            error_message_text = f"{get_message(error_msg_key, user_id)}\\n{get_message(error_details_key, user_id)}{str(e)}"
        except Exception:
             error_message_text = f"An error occurred in draw: {str(e)}"

        if sent_message:
            await bot.edit_message_text(
                error_message_text,
                chat_id=sent_message.chat.id,
                message_id=sent_message.message_id
            )
        else:
            await bot.reply_to(message, error_message_text)
